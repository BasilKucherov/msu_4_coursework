{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate mean cluster radius and inter-cluster distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import librosa\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "import os\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from transforms import *\n",
    "from loss_functions import *\n",
    "from datasets import *\n",
    "from models import *\n",
    "from torchvision.transforms import Compose\n",
    "from clustering_metrics import *\n",
    "\n",
    "train_dataset_path = 'datasets/speech_commands/train'\n",
    "valid_dataset_path = 'datasets/speech_commands/validation'\n",
    "test_dataset_path = 'datasets/speech_commands/test'\n",
    "\n",
    "device = torch.device('cpu')\n",
    "use_gpu = False\n",
    "if torch.cuda.is_available():\n",
    "        use_gpu = True\n",
    "        device = torch.device('cuda', 0)\n",
    "\n",
    "def create_model(model_description):\n",
    "        if 'name' not in model_description:\n",
    "                return '[ERROR]: corrupted model description'\n",
    "\n",
    "        if model_description['name'] == 'DSCNN':\n",
    "                n_mels = model_description['n_mels']\n",
    "                in_shape = (n_mels, 32)\n",
    "                in_channels = model_description['in_channels']\n",
    "                ds_cnn_number = model_description['ds_cnn_number']\n",
    "                ds_cnn_size = model_description['ds_cnn_size']\n",
    "                is_classifier = model_description['is_classifier']\n",
    "                classes_number = 0 if not is_classifier else model_description['classes_number']\n",
    "\n",
    "                return DSCNN(in_channels, in_shape, ds_cnn_number, ds_cnn_size, is_classifier, classes_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from clustering_metrics import *\n",
    "\n",
    "def get_outs(model, dl, device, dataset):\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch in dl:\n",
    "            images = batch['input'].to(device)\n",
    "            images = torch.unsqueeze(images, 1)\n",
    "\n",
    "            labels = batch['target'].to(device)\n",
    "\n",
    "            net_out = model(images)\n",
    "\n",
    "            all_pred += net_out.tolist()\n",
    "            all_labels += labels.tolist()\n",
    "\n",
    "    all_text_labels = []\n",
    "    for label in all_labels:\n",
    "        all_text_labels.append(dataset.get_class_from_idx(label))\n",
    "\n",
    "    return all_pred, all_text_labels\n",
    "\n",
    "def extract_number_from_filename(filename):\n",
    "    try:\n",
    "        return int(filename.split('_')[1])\n",
    "    except (ValueError, IndexError):\n",
    "        return float('inf')\n",
    "\n",
    "def compute_mean_embeddings(all_embeds, all_labels):\n",
    "    unique_labels = np.unique(all_labels)\n",
    "    mean_embeds = {}\n",
    "    cluster_radius = {}\n",
    "\n",
    "    for label in unique_labels:\n",
    "        mask = all_labels == label\n",
    "        embeds_for_label = all_embeds[mask]\n",
    "\n",
    "        mean_embed = np.mean(embeds_for_label, axis=0).tolist()\n",
    "        mean_distance_to_mean_embed = np.mean(np.linalg.norm(embeds_for_label - mean_embed, axis=1))\n",
    "\n",
    "        mean_embeds[str(label)] = mean_embed\n",
    "        cluster_radius[str(label)] = float(mean_distance_to_mean_embed)\n",
    "\n",
    "    return mean_embeds, cluster_radius\n",
    "\n",
    "def experiment_clusters_prototypes(experiment_folder, batch_size, device):\n",
    "    train_dataset_path = 'datasets/speech_commands/train'\n",
    "    valid_dataset_path = 'datasets/speech_commands/validation'\n",
    "    test_dataset_path = 'datasets/speech_commands/test'\n",
    "\n",
    "    experiment_settings_path = os.path.join(experiment_folder, \"experiment_settings.json\")\n",
    "    stats_path = os.path.join(experiment_folder, \"stats.json\")\n",
    "\n",
    "    with open(experiment_settings_path, 'r') as fp:\n",
    "        experiment_settings = json.load(fp)\n",
    "\n",
    "    with open(stats_path, 'r') as fp:\n",
    "        stats = json.load(fp)\n",
    "    \n",
    "    experiment_settings['model']['is_classifier'] = False\n",
    "    model = create_model(experiment_settings['model'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    n_mels = experiment_settings['model']['n_mels']\n",
    "\n",
    "    feature_transform = Compose([ToSTFT(), ToMelSpectrogramFromSTFT(n_mels=n_mels), ToTensor('mel_spectrogram', 'input')])\n",
    "\n",
    "    train_dataset = SpeechCommandsDataset(train_dataset_path,\n",
    "                                Compose([LoadAudio(),\n",
    "                                        FixAudioLength(),\n",
    "                                        feature_transform]))\n",
    "\n",
    "    valid_dataset = SpeechCommandsDataset(valid_dataset_path,\n",
    "                                    Compose([LoadAudio(),\n",
    "                                            FixAudioLength(),\n",
    "                                            feature_transform]))\n",
    "    \n",
    "    test_dataset = SpeechCommandsDataset(test_dataset_path,\n",
    "                                    Compose([LoadAudio(),\n",
    "                                            FixAudioLength(),\n",
    "                                            feature_transform]))\n",
    "\n",
    "\n",
    "    dl_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, prefetch_factor=2)\n",
    "    dl_valid = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=8, prefetch_factor=2)\n",
    "    dl_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=8, prefetch_factor=2)\n",
    "\n",
    "    epochs = stats['clustering_metrics']['fc']['epoch']\n",
    "    checkpoints_folder = os.path.join(experiment_folder, 'checkpoints')\n",
    "\n",
    "    result = {\n",
    "        \"epoch\": [],\n",
    "        \"mean_embed\": [],\n",
    "        \"cluster_radius\": []\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm.tqdm(epochs):\n",
    "        all_embeds = []\n",
    "        all_labels = []\n",
    "        checkpoint_fname = os.path.join(checkpoints_folder, f\"checkpoint_{epoch}\")\n",
    "\n",
    "        checkpoint = torch.load(checkpoint_fname)\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        cur_epoch = checkpoint['epoch']\n",
    "        remove_prefix = 'module.'\n",
    "        state_dict = {k[len(remove_prefix):] if k.startswith(remove_prefix) else k: v for k, v in state_dict.items()}\n",
    "\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        \n",
    "        embeds, labels = get_outs(model, dl_train, device, train_dataset)\n",
    "        all_embeds += embeds\n",
    "        all_labels += labels\n",
    "\n",
    "        embeds, labels = get_outs(model, dl_valid, device, valid_dataset)\n",
    "        all_embeds += embeds\n",
    "        all_labels += labels\n",
    "\n",
    "        embeds, labels = get_outs(model, dl_test, device, test_dataset)\n",
    "        all_embeds += embeds\n",
    "        all_labels += labels\n",
    "\n",
    "        all_embeds = np.array(all_embeds)\n",
    "        all_labels = np.array(all_labels)\n",
    "\n",
    "        mean_embeds, cluster_radius = compute_mean_embeddings(all_embeds, all_labels)\n",
    "\n",
    "        result[\"epoch\"].append(epoch)\n",
    "        result[\"mean_embed\"].append(mean_embeds)\n",
    "        result[\"cluster_radius\"].append(cluster_radius)\n",
    "\n",
    "\n",
    "    \n",
    "    # load stats if exists and add loss\n",
    "    embeds_fpath = os.path.join(experiment_folder, 'embeds.json')\n",
    "\n",
    "    with open(embeds_fpath, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_01',\n",
       " 'base_test',\n",
       " 'lifted_structured_01',\n",
       " 'lifted_structured_02',\n",
       " 'lifted_structured_03',\n",
       " 'lifted_structured_test',\n",
       " 'npair_01',\n",
       " 'npair_02',\n",
       " 'npair_03',\n",
       " 'npair_test',\n",
       " 'silhouette_01',\n",
       " 'silhouette_margin_01',\n",
       " 'triplet_br_01',\n",
       " 'triplet_br_02',\n",
       " 'triplet_br_03',\n",
       " 'triplet_br_04',\n",
       " 'triplet_br_05',\n",
       " 'triplet_br_06',\n",
       " 'triplet_br_07',\n",
       " 'triplet_br_08',\n",
       " 'triplet_br_09',\n",
       " 'triplet_br_test']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_dir = './experiments'\n",
    "\n",
    "items = os.listdir(experiments_dir)\n",
    "to_do_list = [item for item in items if os.path.isdir(os.path.join(experiments_dir, item))]\n",
    "to_do_list = list(sorted(to_do_list))\n",
    "to_do_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start base_01 -- 2023-11-25 23:17:26.892422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d578d1818574fc79e19142406b68eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510><function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>    \n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "Traceback (most recent call last):\n",
      "self._shutdown_workers()    \n",
      "self._shutdown_workers()\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "        if w.is_alive():self._shutdown_workers()\n",
      "    if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "            if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionErrorAssertionError:     : Exception ignored in: can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>can only test a child process\n",
      "\n",
      "\n",
      "\n",
      "AssertionErrorTraceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      ": can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>    \n",
      "\n",
      "Traceback (most recent call last):\n",
      "self._shutdown_workers()Exception ignored in:   File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    Exception ignored in:     self._shutdown_workers()Exception ignored in: if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>\n",
      "\n",
      "\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "      File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "self._shutdown_workers()\n",
      "    self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "self._shutdown_workers()AssertionError\n",
      "    \n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      ": \n",
      "        can only test a child processAssertionError    if w.is_alive():if w.is_alive():if w.is_alive():\n",
      "\n",
      "\n",
      "\n",
      ":   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process            \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "AssertionErrorAssertionErrorAssertionError: : can only test a child process: can only test a child processcan only test a child process\n",
      "\n",
      "\n",
      "Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510><function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510><function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>Exception ignored in: \n",
      "Exception ignored in: Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510><function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "Traceback (most recent call last):\n",
      "        Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "      File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "self._shutdown_workers()self._shutdown_workers()  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "self._shutdown_workers()        \n",
      "\n",
      "    \n",
      "self._shutdown_workers()self._shutdown_workers()  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "self._shutdown_workers()  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "\n",
      "\n",
      "        \n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "      File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "if w.is_alive():if w.is_alive():  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "        \n",
      "\n",
      "    if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():\n",
      "        \n",
      "    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "    \n",
      "AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError    : AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": can only test a child process\n",
      "can only test a child processAssertionErrorcan only test a child processAssertionError\n",
      "AssertionError\n",
      ": : \n",
      ": can only test a child processcan only test a child processcan only test a child process\n",
      "\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "    self._shutdown_workers()  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "        self._shutdown_workers()if w.is_alive():\n",
      "\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "\n",
      "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      ": can only test a child process    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: Exception ignored in: Exception ignored in: Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510><function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510><function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510><function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510><function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "      File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "            self._shutdown_workers()            self._shutdown_workers()self._shutdown_workers()self._shutdown_workers()\n",
      "self._shutdown_workers()self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "\n",
      "\n",
      "\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "      File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "            if w.is_alive():            if w.is_alive():if w.is_alive():if w.is_alive():\n",
      "if w.is_alive():if w.is_alive():\n",
      "if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'            assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "AssertionError\n",
      "\n",
      "\n",
      "AssertionErrorAssertionError: AssertionErrorAssertionErrorAssertionErrorAssertionError: : can only test a child process: : : can only test a child process: \n",
      "can only test a child processcan only test a child processcan only test a child processcan only test a child process\n",
      "can only test a child process\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2708269510>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/basil/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished base_01 -- 2023-11-25 23:18:00.992536 -- 0:00:34.100114\n",
      "Start base_test -- 2023-11-25 23:18:00.992651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4924a6915be8460a9047c5a4b394baa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/basil/Desktop/msu_4_coursework/class_distances.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStart \u001b[39m\u001b[39m{\u001b[39;00mexperiment_name\u001b[39m}\u001b[39;00m\u001b[39m -- \u001b[39m\u001b[39m{\u001b[39;00mstart_time\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m experiment_folder \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(experiments_dir, experiment_name)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m result \u001b[39m=\u001b[39m experiment_clusters_prototypes(experiment_folder, \u001b[39m64\u001b[39;49m, device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m end_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinished \u001b[39m\u001b[39m{\u001b[39;00mexperiment_name\u001b[39m}\u001b[39;00m\u001b[39m -- \u001b[39m\u001b[39m{\u001b[39;00mend_time\u001b[39m}\u001b[39;00m\u001b[39m -- \u001b[39m\u001b[39m{\u001b[39;00mend_time\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart_time\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/basil/Desktop/msu_4_coursework/class_distances.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m embeds, labels \u001b[39m=\u001b[39m get_outs(model, dl_train, device, train_dataset)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m all_embeds \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m embeds\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m all_labels \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\n",
      "\u001b[1;32m/home/basil/Desktop/msu_4_coursework/class_distances.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m all_pred \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m all_labels \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dl:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     images \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/basil/Desktop/msu_4_coursework/class_distances.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     images \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(images, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/msu_4_coursework/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for experiment_name in to_do_list:\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(f\"Start {experiment_name} -- {start_time}\")\n",
    "\n",
    "    experiment_folder = os.path.join(experiments_dir, experiment_name)\n",
    "    result = experiment_clusters_prototypes(experiment_folder, 64, device)\n",
    "    \n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f\"Finished {experiment_name} -- {end_time} -- {end_time - start_time}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
