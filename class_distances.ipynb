{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate mean cluster radius and inter-cluster distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import librosa\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "import os\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from transforms import *\n",
    "from loss_functions import *\n",
    "from datasets import *\n",
    "from models import *\n",
    "from torchvision.transforms import Compose\n",
    "from clustering_metrics import *\n",
    "\n",
    "train_dataset_path = 'datasets/speech_commands/train'\n",
    "valid_dataset_path = 'datasets/speech_commands/validation'\n",
    "test_dataset_path = 'datasets/speech_commands/test'\n",
    "\n",
    "device = torch.device('cpu')\n",
    "use_gpu = False\n",
    "if torch.cuda.is_available():\n",
    "        use_gpu = True\n",
    "        device = torch.device('cuda', 0)\n",
    "\n",
    "def create_model(model_description):\n",
    "        if 'name' not in model_description:\n",
    "                return '[ERROR]: corrupted model description'\n",
    "\n",
    "        if model_description['name'] == 'DSCNN':\n",
    "                n_mels = model_description['n_mels']\n",
    "                in_shape = (n_mels, 32)\n",
    "                in_channels = model_description['in_channels']\n",
    "                ds_cnn_number = model_description['ds_cnn_number']\n",
    "                ds_cnn_size = model_description['ds_cnn_size']\n",
    "                is_classifier = model_description['is_classifier']\n",
    "                classes_number = 0 if not is_classifier else model_description['classes_number']\n",
    "\n",
    "                return DSCNN(in_channels, in_shape, ds_cnn_number, ds_cnn_size, is_classifier, classes_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from clustering_metrics import *\n",
    "\n",
    "def get_outs(model, dl, device, dataset):\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch in dl:\n",
    "            images = batch['input'].to(device)\n",
    "            images = torch.unsqueeze(images, 1)\n",
    "\n",
    "            labels = batch['target'].to(device)\n",
    "\n",
    "            net_out = model(images)\n",
    "\n",
    "            all_pred += net_out.tolist()\n",
    "            all_labels += labels.tolist()\n",
    "\n",
    "    all_text_labels = []\n",
    "    for label in all_labels:\n",
    "        all_text_labels.append(dataset.get_class_from_idx(label))\n",
    "\n",
    "    return all_pred, all_text_labels\n",
    "\n",
    "def extract_number_from_filename(filename):\n",
    "    try:\n",
    "        return int(filename.split('_')[1])\n",
    "    except (ValueError, IndexError):\n",
    "        return float('inf')\n",
    "\n",
    "def compute_mean_embeddings(all_embeds, all_labels):\n",
    "    unique_labels = np.unique(all_labels)\n",
    "    mean_embeds = {}\n",
    "    cluster_radius = {}\n",
    "\n",
    "    for label in unique_labels:\n",
    "        mask = all_labels == label\n",
    "        embeds_for_label = all_embeds[mask]\n",
    "\n",
    "        mean_embed = np.mean(embeds_for_label, axis=0).tolist()\n",
    "        mean_distance_to_mean_embed = np.mean(np.linalg.norm(embeds_for_label - mean_embed, axis=1))\n",
    "\n",
    "        mean_embeds[str(label)] = mean_embed\n",
    "        cluster_radius[str(label)] = float(mean_distance_to_mean_embed)\n",
    "\n",
    "    return mean_embeds, cluster_radius\n",
    "\n",
    "def experiment_clusters_prototypes(experiment_folder, batch_size, device):\n",
    "    train_dataset_path = 'datasets/speech_commands/train'\n",
    "    valid_dataset_path = 'datasets/speech_commands/validation'\n",
    "    test_dataset_path = 'datasets/speech_commands/test'\n",
    "\n",
    "    experiment_settings_path = os.path.join(experiment_folder, \"experiment_settings.json\")\n",
    "    stats_path = os.path.join(experiment_folder, \"stats.json\")\n",
    "\n",
    "    with open(experiment_settings_path, 'r') as fp:\n",
    "        experiment_settings = json.load(fp)\n",
    "\n",
    "    with open(stats_path, 'r') as fp:\n",
    "        stats = json.load(fp)\n",
    "    \n",
    "    experiment_settings['model']['is_classifier'] = False\n",
    "    model = create_model(experiment_settings['model'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    n_mels = experiment_settings['model']['n_mels']\n",
    "\n",
    "    feature_transform = Compose([ToSTFT(), ToMelSpectrogramFromSTFT(n_mels=n_mels), ToTensor('mel_spectrogram', 'input')])\n",
    "\n",
    "    train_dataset = SpeechCommandsDataset(train_dataset_path,\n",
    "                                Compose([LoadAudio(),\n",
    "                                        FixAudioLength(),\n",
    "                                        feature_transform]))\n",
    "\n",
    "    valid_dataset = SpeechCommandsDataset(valid_dataset_path,\n",
    "                                    Compose([LoadAudio(),\n",
    "                                            FixAudioLength(),\n",
    "                                            feature_transform]))\n",
    "    \n",
    "    test_dataset = SpeechCommandsDataset(test_dataset_path,\n",
    "                                    Compose([LoadAudio(),\n",
    "                                            FixAudioLength(),\n",
    "                                            feature_transform]))\n",
    "\n",
    "\n",
    "    dl_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, prefetch_factor=2)\n",
    "    dl_valid = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=8, prefetch_factor=2)\n",
    "    dl_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=8, prefetch_factor=2)\n",
    "\n",
    "    epochs = stats['clustering_metrics']['fc']['epoch']\n",
    "    checkpoints_folder = os.path.join(experiment_folder, 'checkpoints')\n",
    "\n",
    "    result = {\n",
    "        \"epoch\": [],\n",
    "        \"mean_embed\": [],\n",
    "        \"cluster_radius\": []\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm.tqdm(epochs):\n",
    "        all_embeds = []\n",
    "        all_labels = []\n",
    "        checkpoint_fname = os.path.join(checkpoints_folder, f\"checkpoint_{epoch}\")\n",
    "\n",
    "        checkpoint = torch.load(checkpoint_fname)\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        cur_epoch = checkpoint['epoch']\n",
    "        remove_prefix = 'module.'\n",
    "        state_dict = {k[len(remove_prefix):] if k.startswith(remove_prefix) else k: v for k, v in state_dict.items()}\n",
    "\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        \n",
    "        embeds, labels = get_outs(model, dl_train, device, train_dataset)\n",
    "        all_embeds += embeds\n",
    "        all_labels += labels\n",
    "\n",
    "        embeds, labels = get_outs(model, dl_valid, device, valid_dataset)\n",
    "        all_embeds += embeds\n",
    "        all_labels += labels\n",
    "\n",
    "        embeds, labels = get_outs(model, dl_test, device, test_dataset)\n",
    "        all_embeds += embeds\n",
    "        all_labels += labels\n",
    "\n",
    "        all_embeds = np.array(all_embeds)\n",
    "        all_labels = np.array(all_labels)\n",
    "\n",
    "        mean_embeds, cluster_radius = compute_mean_embeddings(all_embeds, all_labels)\n",
    "\n",
    "        result[\"epoch\"].append(epoch)\n",
    "        result[\"mean_embed\"].append(mean_embeds)\n",
    "        result[\"cluster_radius\"].append(cluster_radius)\n",
    "\n",
    "\n",
    "    \n",
    "    # load stats if exists and add loss\n",
    "    embeds_fpath = os.path.join(experiment_folder, 'embeds.json')\n",
    "\n",
    "    with open(embeds_fpath, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_01',\n",
       " 'base_test',\n",
       " 'lifted_structured_01',\n",
       " 'lifted_structured_02',\n",
       " 'lifted_structured_03',\n",
       " 'lifted_structured_test',\n",
       " 'npair_01',\n",
       " 'npair_02',\n",
       " 'npair_03',\n",
       " 'npair_test',\n",
       " 'silhouette_01',\n",
       " 'silhouette_margin_01',\n",
       " 'triplet_br_01',\n",
       " 'triplet_br_02',\n",
       " 'triplet_br_03',\n",
       " 'triplet_br_04',\n",
       " 'triplet_br_05',\n",
       " 'triplet_br_06',\n",
       " 'triplet_br_07',\n",
       " 'triplet_br_08',\n",
       " 'triplet_br_09',\n",
       " 'triplet_br_test']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_dir = './experiments'\n",
    "\n",
    "items = os.listdir(experiments_dir)\n",
    "to_do_list = [item for item in items if os.path.isdir(os.path.join(experiments_dir, item))]\n",
    "to_do_list = list(sorted(to_do_list))\n",
    "to_do_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start base_01 -- 2023-11-25 23:19:05.043675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8699ee62b554de486d3e81c6a01dbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished base_01 -- 2023-11-25 23:41:21.783334 -- 0:22:16.739659\n",
      "Start base_test -- 2023-11-25 23:41:21.783449\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc1e1967f804b579841a32c189b7733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished base_test -- 2023-11-26 00:03:23.771777 -- 0:22:01.988328\n",
      "Start lifted_structured_01 -- 2023-11-26 00:03:23.771883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc35399a6bf844f4ba5c228283b17bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished lifted_structured_01 -- 2023-11-26 00:25:24.576057 -- 0:22:00.804174\n",
      "Start lifted_structured_02 -- 2023-11-26 00:25:24.576161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e9e4b4976648959cad106c0328c3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished lifted_structured_02 -- 2023-11-26 00:47:27.424695 -- 0:22:02.848534\n",
      "Start lifted_structured_03 -- 2023-11-26 00:47:27.424807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4f3fc7c4e2442daa5eb037fa956a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished lifted_structured_03 -- 2023-11-26 01:40:21.960010 -- 0:52:54.535203\n",
      "Start lifted_structured_test -- 2023-11-26 01:40:21.960118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fcf7cf543b4ec7b0d11e8f4bd8f167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished lifted_structured_test -- 2023-11-26 02:01:50.961048 -- 0:21:29.000930\n",
      "Start npair_01 -- 2023-11-26 02:01:50.961151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104726fa222f47d096bb472f0b7b62f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished npair_01 -- 2023-11-26 02:23:10.550906 -- 0:21:19.589755\n",
      "Start npair_02 -- 2023-11-26 02:23:10.551011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2945d47f5d4f59bc7336d274b89a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished npair_02 -- 2023-11-26 02:44:31.536278 -- 0:21:20.985267\n",
      "Start npair_03 -- 2023-11-26 02:44:31.536389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe6efbf04b7497485f22ab5958b4525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished npair_03 -- 2023-11-26 03:05:56.072153 -- 0:21:24.535764\n",
      "Start npair_test -- 2023-11-26 03:05:56.072262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eea58da7c0e4ebe985ba8653a5516a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished npair_test -- 2023-11-26 03:27:22.719460 -- 0:21:26.647198\n",
      "Start silhouette_01 -- 2023-11-26 03:27:22.719564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23360f5d5bce4e1b94d1a53ca556fe7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished silhouette_01 -- 2023-11-26 03:48:46.065621 -- 0:21:23.346057\n",
      "Start silhouette_margin_01 -- 2023-11-26 03:48:46.065728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b029456d38e04cf9b65abd22dcff2814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished silhouette_margin_01 -- 2023-11-26 04:10:04.028295 -- 0:21:17.962567\n",
      "Start triplet_br_01 -- 2023-11-26 04:10:04.028397\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc789dd906e4469fb5964aef1cd37989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_01 -- 2023-11-26 04:31:27.998507 -- 0:21:23.970110\n",
      "Start triplet_br_02 -- 2023-11-26 04:31:27.998613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82e99906678484ca1ff8c5936ca1f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_02 -- 2023-11-26 04:52:53.519029 -- 0:21:25.520416\n",
      "Start triplet_br_03 -- 2023-11-26 04:52:53.519135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7907acd259ae4f1e8ce5b58dfa6a3ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_03 -- 2023-11-26 05:13:41.871264 -- 0:20:48.352129\n",
      "Start triplet_br_04 -- 2023-11-26 05:13:41.871377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501af1a334bf4ef498b8c9166b6b6398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_04 -- 2023-11-26 05:37:00.416750 -- 0:23:18.545373\n",
      "Start triplet_br_05 -- 2023-11-26 05:37:00.416854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810d1056320d421ab3d113d0986a98ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_05 -- 2023-11-26 06:07:31.590533 -- 0:30:31.173679\n",
      "Start triplet_br_06 -- 2023-11-26 06:07:31.590642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a979975a5d34121ad128115ab1bb7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_06 -- 2023-11-26 06:28:58.840547 -- 0:21:27.249905\n",
      "Start triplet_br_07 -- 2023-11-26 06:28:58.840652\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac2b35169474da7966406f743a8da3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_07 -- 2023-11-26 07:03:05.124860 -- 0:34:06.284208\n",
      "Start triplet_br_08 -- 2023-11-26 07:03:05.124966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3db28c4eb04bd7916a4ab02975fdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_08 -- 2023-11-26 08:21:33.204335 -- 1:18:28.079369\n",
      "Start triplet_br_09 -- 2023-11-26 08:21:33.204438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea54ee64ef91437591adac801a65357f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_09 -- 2023-11-26 09:14:34.453724 -- 0:53:01.249286\n",
      "Start triplet_br_test -- 2023-11-26 09:14:34.453828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38b4f799ed1441c917b8e102eab5e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished triplet_br_test -- 2023-11-26 09:36:18.406328 -- 0:21:43.952500\n"
     ]
    }
   ],
   "source": [
    "for experiment_name in to_do_list:\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(f\"Start {experiment_name} -- {start_time}\")\n",
    "\n",
    "    experiment_folder = os.path.join(experiments_dir, experiment_name)\n",
    "    result = experiment_clusters_prototypes(experiment_folder, 64, device)\n",
    "    \n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f\"Finished {experiment_name} -- {end_time} -- {end_time - start_time}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
