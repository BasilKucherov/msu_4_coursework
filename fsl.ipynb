{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from transforms import *\n",
    "from loss_functions import *\n",
    "from datasets import *\n",
    "from models import *\n",
    "from torchvision.transforms import Compose\n",
    "from clustering_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.device'> cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "use_gpu = False\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "    device = torch.device('cuda', 0)\n",
    "    \n",
    "print(type(device), device)\n",
    "\n",
    "# may benefit if network size/input/output is stable\n",
    "if use_gpu:\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_description):\n",
    "        if 'name' not in model_description:\n",
    "                return '[ERROR]: corrupted model description'\n",
    "\n",
    "        if model_description['name'] == 'DSCNN':\n",
    "                n_mels = model_description['n_mels']\n",
    "                in_shape = (n_mels, 32)\n",
    "                in_channels = model_description['in_channels']\n",
    "                ds_cnn_number = model_description['ds_cnn_number']\n",
    "                ds_cnn_size = model_description['ds_cnn_size']\n",
    "                is_classifier = model_description['is_classifier']\n",
    "                classes_number = 0 if not is_classifier else model_description['classes_number']\n",
    "\n",
    "                return DSCNN(in_channels, in_shape, ds_cnn_number, ds_cnn_size, is_classifier, classes_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierClosestKnown():\n",
    "    def __init__(self, embedding_block, embedding_size, device):\n",
    "        self.device = device\n",
    "        self.embedding_block = embedding_block\n",
    "        self.embedding_size = embedding_size\n",
    "        self.freeze(self.embedding_block)\n",
    "\n",
    "        self.class_ids = torch.empty((0, ), dtype=torch.int32)\n",
    "        self.class_names = []\n",
    "        self.class_embeddings = torch.empty((0, self.embedding_size), dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.current_id = 0\n",
    "    \n",
    "    def freeze(self, block) -> None:\n",
    "        for p in block.parameters():\n",
    "            p.requires_grad = False\n",
    "        block.eval()\n",
    "\n",
    "    def add_class(self, input, label):\n",
    "        embed = self.embedding_block(input.to(self.device))\n",
    "        mean_embed = torch.mean(embed, dim=0).unsqueeze(0)\n",
    "\n",
    "        self.class_embeddings = torch.cat((self.class_embeddings, mean_embed), dim=0)\n",
    "        self.class_names.append(label)\n",
    "        self.class_ids = torch.cat((self.class_ids, torch.tensor([self.current_id], dtype=torch.int32)))\n",
    "        self.current_id += 1\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.class_names\n",
    "\n",
    "    def classify(self, inputs):\n",
    "        input_embed = self.embedding_block(inputs.to(self.device))\n",
    "        distances = torch.cdist(input_embed, self.class_embeddings)  # Compute distances between input embeddings and class embeddings\n",
    "\n",
    "        closest_ids = torch.argmin(distances, dim=1).cpu().tolist()  # Find the index of the closest known embedding for each input\n",
    "        labels = [self.class_names[id] for id in closest_ids]  # Get the corresponding class labels\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_class_batch(dataset, class_indices, samples_number, class_idx):\n",
    "    indexes = np.random.choice(class_indices[class_idx], samples_number, replace=False)\n",
    "\n",
    "    batch = []\n",
    "\n",
    "    for i in indexes:\n",
    "        item = dataset.__getitem__(i)\n",
    "        batch.append(item['input'])\n",
    "    \n",
    "    batch = torch.stack(batch, dim=0)\n",
    "    return batch\n",
    "\n",
    "def eval_experiment_closest_known(experiments_folder, experiment_name, epochs_to_test=[], fsl_examples=5, random_seed=42):\n",
    "    experiment_folder = os.path.join(experiments_folder, experiment_name)\n",
    "\n",
    "    experiment_settings_path = os.path.join(experiment_folder, \"experiment_settings.json\")\n",
    "    experiment_stats_path = os.path.join(experiment_folder, \"stats.json\")\n",
    "\n",
    "    experiment_stats = {}\n",
    "    if os.path.isfile(experiment_stats_path):\n",
    "        with open(experiment_stats_path, 'r') as fp:\n",
    "            experiment_stats = json.load(fp)\n",
    "\n",
    "    with open(experiment_settings_path, 'r') as fp:\n",
    "        experiment_settings = json.load(fp)\n",
    "\n",
    "\n",
    "    ''' create model '''\n",
    "    experiment_settings['model']['is_classifier'] = False\n",
    "    model = create_model(experiment_settings['model'])\n",
    "\n",
    "    n_mels = experiment_settings['model']['n_mels']\n",
    "    embedding_size = experiment_settings['model']['ds_cnn_size']\n",
    "\n",
    "    ''' prepare datasets '''\n",
    "    test_dataset_path = 'datasets/speech_commands/test'\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    feature_transform = Compose([ToSTFT(), ToMelSpectrogramFromSTFT(n_mels=n_mels), ToTensor('mel_spectrogram', 'input')])\n",
    "\n",
    "\n",
    "    test_dataset = SpeechCommandsDataset(test_dataset_path,\n",
    "                                    Compose([LoadAudio(),\n",
    "                                            FixAudioLength(),\n",
    "                                            feature_transform]))\n",
    "\n",
    "    dl_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=16, prefetch_factor=2)\n",
    "    test_indices = test_dataset.get_class_indices()\n",
    "    test_classes = test_dataset.classes\n",
    "\n",
    "    ''' Prepare train data '''\n",
    "    np.random.seed(random_seed)\n",
    "    n_samples = fsl_examples\n",
    "    classifier_train_batches = []\n",
    "    classifier_train_labels = []\n",
    "        \n",
    "    for class_name in test_classes:\n",
    "        class_idx = test_dataset.get_idx_from_class(class_name)\n",
    "        classifier_train_batches.append(form_class_batch(test_dataset, test_indices, n_samples, class_idx))\n",
    "        classifier_train_labels.append(class_name)\n",
    "\n",
    "    all_class_names = test_classes\n",
    "    class_name_to_idx = {class_name: i for i, class_name in enumerate(all_class_names)} \n",
    "\n",
    "    ''' get epochs to test '''\n",
    "    if not epochs_to_test:\n",
    "        for key in experiment_stats['clustering_metrics']:\n",
    "            epochs_to_test.append(experiment_stats['clustering_metrics'][key]['best_train_epoch'])\n",
    "            epochs_to_test.append(experiment_stats['clustering_metrics'][key]['best_valid_epoch'])\n",
    "            epochs_to_test.append(experiment_stats['clustering_metrics'][key]['best_test_epoch'])\n",
    "        \n",
    "        epochs_to_test.append(experiment_stats['loss']['train_best_epoch'])\n",
    "        epochs_to_test.append(experiment_stats['loss']['valid_best_epoch'])\n",
    "\n",
    "    epochs_to_test = set(epochs_to_test)\n",
    "\n",
    "    ''' actual testing '''\n",
    "    print(f\"Epochs to test: {epochs_to_test}\")\n",
    "\n",
    "    for epoch in epochs_to_test:\n",
    "        print(f\"{epoch} \", end=\"\")\n",
    "        checkpoint_fname = os.path.join(experiment_folder, 'checkpoints', f'checkpoint_{epoch}')\n",
    "\n",
    "        checkpoint = torch.load(checkpoint_fname)\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        cur_epoch = checkpoint['epoch']\n",
    "        remove_prefix = 'module.'\n",
    "        state_dict = {k[len(remove_prefix):] if k.startswith(remove_prefix) else k: v for k, v in state_dict.items()}\n",
    "\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        model.freeze()\n",
    "\n",
    "        em_classifier = ClassifierClosestKnown(model, embedding_size, device)\n",
    "\n",
    "        ''' Actual Training of classifier'''\n",
    "        for i, batch in enumerate(classifier_train_batches):\n",
    "            batch = torch.unsqueeze(batch, 1)\n",
    "            em_classifier.add_class(batch, classifier_train_labels[i])\n",
    "\n",
    "        ''' test classifier on test'''\n",
    "        test_true_labels = []\n",
    "        test_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_test:\n",
    "                input = torch.unsqueeze(batch['input'].to(device), 1)\n",
    "\n",
    "                target = [test_dataset.get_class_from_idx(item.item()) for item in batch['target']]\n",
    "                target_idx = [class_name_to_idx[t] for t in target]\n",
    "\n",
    "                prediction = em_classifier.classify(input)\n",
    "                prediction_idx = [class_name_to_idx[p] for p in prediction]\n",
    "\n",
    "                test_predictions += prediction_idx\n",
    "                test_true_labels += target_idx\n",
    "        \n",
    "        test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "\n",
    "        fsl_key = f'closest_known_epoch{epoch}_shots{fsl_examples}'\n",
    "\n",
    "        if 'fsl_only_test' not in experiment_stats.keys():\n",
    "            experiment_stats['fsl_only_test'] = {}\n",
    "\n",
    "        if fsl_key in experiment_stats['fsl_only_test'].keys():\n",
    "            if not isinstance(experiment_stats['fsl_only_test'][fsl_key]['accuracy'], list):\n",
    "                experiment_stats['fsl_only_test'][fsl_key]['accuracy'] = [experiment_stats['fsl_only_test'][fsl_key]['accuracy']]\n",
    "            experiment_stats['fsl_only_test'][fsl_key]['accuracy'].append(test_accuracy)\n",
    "        else:\n",
    "            experiment_stats['fsl_only_test'][fsl_key] = {\n",
    "                \"epoch\": epoch,\n",
    "                \"shots\": fsl_examples,\n",
    "                \"accuracy\": test_accuracy\n",
    "            }\n",
    "    print()\n",
    "    with open(experiment_stats_path, \"w\") as fp:\n",
    "        json.dump(experiment_stats, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "experiments_folder = './experiments'\n",
    "\n",
    "items = os.listdir(experiments_folder)\n",
    "to_do_list = [item for item in items if os.path.isdir(os.path.join(experiments_folder, item))]\n",
    "to_do_list = sorted(to_do_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_01',\n",
       " 'lifted_structured_01',\n",
       " 'lifted_structured_02',\n",
       " 'npair_01',\n",
       " 'npair_02',\n",
       " 'npair_03',\n",
       " 'triplet_br_01',\n",
       " 'triplet_br_02',\n",
       " 'triplet_br_03',\n",
       " 'triplet_br_04',\n",
       " 'triplet_br_05',\n",
       " 'triplet_br_06',\n",
       " 'triplet_br_07',\n",
       " 'triplet_br_08']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_do_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----base_01-----\n",
      "-----lifted_structured_01-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36cc15025a1448ba7b9e5908a64537f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "seed = 671155:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "seed = 131932:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "seed = 365838:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "seed = 259178:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "seed = 644167:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "seed = 110268:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "seed = 732180:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "seed = 54886:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "seed = 137337:\n",
      "Epochs to test: {45, 190}\n",
      "45 190 \n",
      "-----lifted_structured_02-----\n",
      "-----npair_01-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79ab53881854f55ba8d3df404171908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "seed = 671155:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "seed = 131932:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "seed = 365838:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "seed = 259178:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "seed = 644167:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "seed = 110268:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "seed = 732180:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "seed = 54886:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "seed = 137337:\n",
      "Epochs to test: {40, 20, 60}\n",
      "40 20 60 \n",
      "-----npair_02-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3558ae7572c4d7a9a72cc9f02dc28a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "seed = 671155:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "seed = 131932:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "seed = 365838:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "seed = 259178:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "seed = 644167:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "seed = 110268:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "seed = 732180:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "seed = 54886:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "seed = 137337:\n",
      "Epochs to test: {35, 20, 55}\n",
      "35 20 55 \n",
      "-----npair_03-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b400b12b70849c485b179a5b1bdc83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "seed = 671155:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "seed = 131932:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "seed = 365838:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "seed = 259178:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "seed = 644167:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "seed = 110268:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "seed = 732180:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "seed = 54886:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "seed = 137337:\n",
      "Epochs to test: {35, 85, 30, 95}\n",
      "35 85 30 95 \n",
      "-----triplet_br_01-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcd835b50a542549ce6b7d58aab4c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "seed = 671155:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "seed = 131932:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "seed = 365838:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "seed = 259178:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "seed = 644167:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "seed = 110268:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "seed = 732180:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "seed = 54886:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "seed = 137337:\n",
      "Epochs to test: {160, 5, 175}\n",
      "160 5 175 \n",
      "-----triplet_br_02-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4286fe74e3d44428366492dc459ee6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "seed = 671155:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "seed = 131932:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "seed = 365838:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "seed = 259178:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "seed = 644167:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "seed = 110268:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "seed = 732180:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "seed = 54886:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "seed = 137337:\n",
      "Epochs to test: {160, 130, 75}\n",
      "160 130 75 \n",
      "-----triplet_br_03-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2902485db5214fed8b6cb4800aa411d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "seed = 671155:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "seed = 131932:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "seed = 365838:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "seed = 259178:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "seed = 644167:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "seed = 110268:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "seed = 732180:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "seed = 54886:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "seed = 137337:\n",
      "Epochs to test: {185, 75, 190}\n",
      "185 75 190 \n",
      "-----triplet_br_04-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65ec4f8eb9d460b9aa38fd821c89d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "seed = 671155:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "seed = 131932:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "seed = 365838:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "seed = 259178:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "seed = 644167:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "seed = 110268:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "seed = 732180:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "seed = 54886:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "seed = 137337:\n",
      "Epochs to test: {80, 195, 60}\n",
      "80 195 60 \n",
      "-----triplet_br_05-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec802aa5fa9475f9d4812622888d070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "seed = 671155:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "seed = 131932:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "seed = 365838:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "seed = 259178:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "seed = 644167:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "seed = 110268:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "seed = 732180:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "seed = 54886:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "seed = 137337:\n",
      "Epochs to test: {185}\n",
      "185 \n",
      "-----triplet_br_06-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7fd3462680435483f29ec26e6d5614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "seed = 671155:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "seed = 131932:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "seed = 365838:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "seed = 259178:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "seed = 644167:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "seed = 110268:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "seed = 732180:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "seed = 54886:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "seed = 137337:\n",
      "Epochs to test: {40}\n",
      "40 \n",
      "-----triplet_br_07-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe48a70a28944679a6cd8ecad696535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "seed = 671155:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "seed = 131932:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "seed = 365838:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "seed = 259178:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "seed = 644167:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "seed = 110268:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "seed = 732180:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "seed = 54886:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "seed = 137337:\n",
      "Epochs to test: {125, 45, 175}\n",
      "125 45 175 \n",
      "-----triplet_br_08-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe336b289a48446284a6ec4f9b9e4790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 121958:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n",
      "seed = 671155:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n",
      "seed = 131932:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n",
      "seed = 365838:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n",
      "seed = 259178:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n",
      "seed = 644167:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n",
      "seed = 110268:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n",
      "seed = 732180:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n",
      "seed = 54886:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n",
      "seed = 137337:\n",
      "Epochs to test: {145, 140}\n",
      "145 140 \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "seeds = np.random.randint(0, 1000000, 10)\n",
    "\n",
    "\n",
    "for experiment_name in to_do_list:\n",
    "    print(f\"-----{experiment_name}-----\")\n",
    "    experiment_folder = os.path.join(experiments_folder, experiment_name)\n",
    "\n",
    "    experiment_settings_path = os.path.join(experiment_folder, \"experiment_settings.json\")\n",
    "    experiment_stats_path = os.path.join(experiment_folder, \"stats.json\")\n",
    "\n",
    "    with open(os.path.join(experiment_folder, 'stats.json'), 'r') as fp:\n",
    "        experiment_stats = json.load(fp)\n",
    "\n",
    "    done_epochs = []\n",
    "    for key, fsl in experiment_stats['fsl_only_test'].items():\n",
    "        done_epochs.append(fsl['epoch'])\n",
    "    \n",
    "    epochs_to_test = []\n",
    "    new_epochs_to_test = []\n",
    "    for key in experiment_stats['clustering_metrics']:\n",
    "        epochs_to_test.append(experiment_stats['clustering_metrics'][key]['best_test_epoch'])\n",
    "\n",
    "    epochs_to_test = set(epochs_to_test)\n",
    "    done_epochs = set(done_epochs)\n",
    "\n",
    "    for epoch in epochs_to_test:\n",
    "        if epoch not in done_epochs:\n",
    "            new_epochs_to_test.append(epoch)\n",
    "\n",
    "    if len(new_epochs_to_test) > 0:\n",
    "        for i in tqdm.tqdm(range(10)):\n",
    "            print(f\"seed = {seeds[i]}:\")\n",
    "            eval_experiment_closest_known(experiments_folder, experiment_name, epochs_to_test=new_epochs_to_test, fsl_examples=5, random_seed=seeds[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
